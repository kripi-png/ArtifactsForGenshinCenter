# by kripi-png
# combines dataset.json and new_artifacts.json
# does not generate a new json but edits dataset.json

import json
import os
import shutil

# use the file location instead of the current working dir
# so the scripts can be called anywhere rather than only inside new_artifacts/
ARTIFACTS_DIR = os.path.dirname(__file__)

# file generated by scraper.py consisting of new artifacts not included in old dataset.json
NEW_ARTIFACTS_PATH = os.path.join(ARTIFACTS_DIR, "new_artifacts.json")

# prioritized locations for the dataset.json
# if there is no dataset.json in the current directory
# create a copy of src/dataset in there to be used
LOCAL_DATASET_PATH = os.path.join(ARTIFACTS_DIR, "./dataset.json")
SRC_DATASET_PATH = os.path.join(ARTIFACTS_DIR, "../src/dataset.json")


def get_dataset_path():
    """
    If dataset.json exists in new_artifacts directory, return the path.
    If src/dataset.json exists, create a copy of it in new_artifacts directory and return the path.
    Otherwise, raise FileNotFoundError.
    """
    if os.path.isfile(LOCAL_DATASET_PATH):
        return LOCAL_DATASET_PATH
    if os.path.isfile(SRC_DATASET_PATH):
        # create copy
        shutil.copyfile(SRC_DATASET_PATH, LOCAL_DATASET_PATH)
        return LOCAL_DATASET_PATH

    raise FileNotFoundError("No dataset.json found.")


def get_dataset_data(dataset_path: str):
    """Returns the contents of dataset.json or raises FileNotFoundError."""
    # technically done already in get_dataset_path() but just in case
    if not os.path.isfile(dataset_path):
        raise FileNotFoundError("No dataset.json found.")

    with open(dataset_path, "r") as f:
        return json.load(f)


def get_new_artifacts_data(new_artifacts_path: str):
    """Returns the contents of new_artifacts.json or raises FileNotFoundError."""
    if not os.path.isfile(new_artifacts_path):
        raise FileNotFoundError(
            "No new_artifacts.json found. Please run scraper.py first."
        )

    with open(new_artifacts_path, "r") as f:
        return json.load(f)


def main():
    # find out file path to use and get the dataset data
    dataset_path = get_dataset_path()
    dataset = get_dataset_data(dataset_path)

    # get new artifacts
    new_artifacts = get_new_artifacts_data(NEW_ARTIFACTS_PATH)

    # keep track of updated sets for logging
    updated = []
    for set in new_artifacts:
        dataset[set] = new_artifacts[set]
        updated.append(set)

    # update the dataset file
    with open(dataset_path, "w") as f:
        json.dump(dataset, f)

    print("Added the following sets: ")
    [print("-", set) for set in updated]


main()
